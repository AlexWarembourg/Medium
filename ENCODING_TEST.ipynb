{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d</th>\n",
       "      <th>y</th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_015_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_015</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_701</td>\n",
       "      <td>5</td>\n",
       "      <td>2012-12-29</td>\n",
       "      <td>11249</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_033_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_033</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_701</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-12-29</td>\n",
       "      <td>11249</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_150_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_150</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_701</td>\n",
       "      <td>5</td>\n",
       "      <td>2012-12-29</td>\n",
       "      <td>11249</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_165_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_165</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_701</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-12-29</td>\n",
       "      <td>11249</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_336_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_336</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_701</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-12-29</td>\n",
       "      <td>11249</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id        item_id    dept_id   cat_id store_id  \\\n",
       "0  HOBBIES_1_015_CA_1_evaluation  HOBBIES_1_015  HOBBIES_1  HOBBIES     CA_1   \n",
       "1  HOBBIES_1_033_CA_1_evaluation  HOBBIES_1_033  HOBBIES_1  HOBBIES     CA_1   \n",
       "2  HOBBIES_1_150_CA_1_evaluation  HOBBIES_1_150  HOBBIES_1  HOBBIES     CA_1   \n",
       "3  HOBBIES_1_165_CA_1_evaluation  HOBBIES_1_165  HOBBIES_1  HOBBIES     CA_1   \n",
       "4  HOBBIES_1_336_CA_1_evaluation  HOBBIES_1_336  HOBBIES_1  HOBBIES     CA_1   \n",
       "\n",
       "  state_id      d  y       date  wm_yr_wk event_name_1 event_type_1  \\\n",
       "0       CA  d_701  5 2012-12-29     11249          NaN          NaN   \n",
       "1       CA  d_701  0 2012-12-29     11249          NaN          NaN   \n",
       "2       CA  d_701  5 2012-12-29     11249          NaN          NaN   \n",
       "3       CA  d_701  0 2012-12-29     11249          NaN          NaN   \n",
       "4       CA  d_701  0 2012-12-29     11249          NaN          NaN   \n",
       "\n",
       "  event_name_2 event_type_2  snap_CA  snap_TX  snap_WI  \n",
       "0          NaN          NaN        0        0        0  \n",
       "1          NaN          NaN        0        0        0  \n",
       "2          NaN          NaN        0        0        0  \n",
       "3          NaN          NaN        0        0        0  \n",
       "4          NaN          NaN        0        0        0  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "HORIZON = 28 # horizon de forecast\n",
    "CAT_COLS = ['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id']\n",
    "np.random.seed(25)\n",
    "\n",
    "row_sales = pd.read_csv(\"C:/Users/n000193384/Downloads/awa_mooc/src/data/sales_train_evaluation.csv\")\n",
    "sample_ts = np.random.choice(row_sales['id'], (750,))\n",
    "\n",
    "skip = [f\"d_{i}\" for i in range(1, 700 + 1)] \n",
    "row_sales = row_sales.loc[row_sales['id'].isin(sample_ts)].drop(skip, axis=1)\n",
    "\n",
    "\n",
    "calendar = pd.read_csv(\"C:/Users/n000193384/Downloads/awa_mooc/src/data/calendar.csv\", \n",
    "                       parse_dates=['date'],\n",
    "                       usecols=['date', 'd', 'wm_yr_wk', 'event_name_1', 'event_name_2', \n",
    "                                'event_type_1', 'event_type_2',\n",
    "                                'snap_CA', 'snap_TX', 'snap_WI']\n",
    ")\n",
    "\n",
    "# formattage ligne et renommage des colonnes pour respecter les conventions de la librairie.\n",
    "train = (row_sales\n",
    "         .pipe(pd.melt, \n",
    "               id_vars=[\"id\"] + CAT_COLS,\n",
    "               var_name='d',\n",
    "               value_name=\"y\"\n",
    "               )\n",
    "         .merge(calendar, how=\"left\", on=[\"d\"])\n",
    "         .assign(date= lambda x : pd.to_datetime(x['date']))\n",
    "        )\n",
    "\n",
    "train.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's forecast the next 28 days with minimal features and explore different encoding method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_validation = train[\"date\"].max()\n",
    "start_validation = end_validation - pd.DateOffset(days=HORIZON)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will define direct forecasting model, 28 lags and encoding feature + few temporal feature such as [dow, week, month]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "lags_feat = [f\"lag{i+HORIZON}\" for i in np.arange(HORIZON+1)]\n",
    "temporal_feat = [\"month\", \"dow\", \"week\"] \n",
    "\n",
    "# lags.\n",
    "X = (train\n",
    "     .sort_values(by=[\"id\", \"date\"])\n",
    "     .assign(\n",
    "         month = lambda x : x[\"date\"].dt.month,\n",
    "         dow = lambda x : x[\"date\"].dt.dayofweek,\n",
    "         week = lambda x : np.int64(x[\"date\"].dt.isocalendar().week),\n",
    "         **{f\"lag{i+HORIZON}\":train.groupby('id')[\"y\"].transform(lambda x : x.shift(i+HORIZON)) for i in np.arange(HORIZON+1)})\n",
    "     )[[\"id\", \"date\", \"y\"] +  CAT_COLS + temporal_feat + lags_feat].copy()\n",
    "\n",
    "X_tr = X.loc[X[\"date\"] < start_validation]\n",
    "X_tst = X.loc[X[\"date\"] >= start_validation]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LabelEncoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb \n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "model_params = {\n",
    "    'verbose': -1,\n",
    "    'force_col_wise': True,\n",
    "    'num_leaves': 100,\n",
    "    'n_estimators': 250,\n",
    "}\n",
    "model = lgb.LGBMRegressor(**model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_id = 663\n",
      "dept_id = 7\n",
      "cat_id = 3\n",
      "store_id = 10\n",
      "state_id = 3\n"
     ]
    }
   ],
   "source": [
    "for c in CAT_COLS:\n",
    "    print(f\"{c} = {X[c].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "cardinal_cat_cols = ['item_id', 'store_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\n000193384\\AppData\\Local\\Temp\\ipykernel_2744\\1383321429.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_tr[f'lb_{c}'] = Lb.fit_transform(X_tr[c])\n",
      "C:\\Users\\n000193384\\AppData\\Local\\Temp\\ipykernel_2744\\1383321429.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_tst[f\"lb_{c}\"] = Lb.transform(X_tst[c])\n",
      "C:\\Users\\n000193384\\AppData\\Local\\Temp\\ipykernel_2744\\1383321429.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_tr[f'lb_{c}'] = Lb.fit_transform(X_tr[c])\n",
      "C:\\Users\\n000193384\\AppData\\Local\\Temp\\ipykernel_2744\\1383321429.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_tst[f\"lb_{c}\"] = Lb.transform(X_tst[c])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean absolute erro is 5.476048650982964 and bias equals to -0.21834726003399485\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "Lb = LabelEncoder()\n",
    "lb_feat = []\n",
    "for c in cardinal_cat_cols:\n",
    "    X_tr[f'lb_{c}'] = Lb.fit_transform(X_tr[c])\n",
    "    X_tst[f\"lb_{c}\"] = Lb.transform(X_tst[c])\n",
    "    lb_feat.append(f\"lb_{c}\")\n",
    "    \n",
    "model.fit(X_tr[temporal_feat + lags_feat + lb_feat].astype(float), X_tr['y'])\n",
    "yhat = model.predict(X_tst[temporal_feat + lags_feat + lb_feat].astype(float))\n",
    "mae = mean_absolute_error(X_tst['y'], yhat, sample_weight=X_tst[\"y\"])\n",
    "bias = np.mean(yhat - X_tst['y'])\n",
    "\n",
    "print(f\"mean absolute erro is {mae} and bias equals to {bias}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Onehot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean absolute erro is 5.410876897774181 and bias equals to -0.19952225117447575\n"
     ]
    }
   ],
   "source": [
    "cp_X = X.copy()\n",
    "cols_dict = {}\n",
    "for c in cardinal_cat_cols:\n",
    "    ohe_ds = pd.get_dummies(X[c], prefix=\"ohe\").astype(np.uint8)\n",
    "    ohe_cols = ohe_ds.columns.tolist()\n",
    "    cp_X = pd.concat((cp_X, ohe_ds), axis=1)\n",
    "    cols_dict[c] = ohe_cols\n",
    "    del ohe_ds\n",
    "    \n",
    "\n",
    "X_tr = cp_X.loc[cp_X[\"date\"] < start_validation]\n",
    "X_tst = cp_X.loc[cp_X[\"date\"] >= start_validation]\n",
    "\n",
    "ohe_feat = cols_dict['item_id'] + cols_dict['store_id']\n",
    "\n",
    "model.fit(X_tr[temporal_feat + lags_feat + ohe_feat], X_tr['y'])\n",
    "yhat = model.predict(X_tst[temporal_feat + lags_feat + ohe_feat])\n",
    "mae = mean_absolute_error(X_tst['y'], yhat, sample_weight=X_tst[\"y\"])\n",
    "bias = np.mean(yhat - X_tst['y'])\n",
    "\n",
    "print(f\"mean absolute erro is {mae} and bias equals to {bias}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STATIC Target Encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean absolute erro is 5.288595300345391 and bias equals to -0.24375465440947097\n"
     ]
    }
   ],
   "source": [
    "ste_feat = []\n",
    "for c in cardinal_cat_cols:\n",
    "    fname = f\"te_{c}_mean\"\n",
    "    te_feat = X_tr.groupby(c)[\"y\"].mean().to_frame(fname).reset_index()\n",
    "    X_tr = pd.merge(X_tr, te_feat, how=\"left\", on=[c])\n",
    "    X_tst = pd.merge(X_tst, te_feat, how=\"left\", on=[c])\n",
    "    ste_feat.append(fname)\n",
    "    \n",
    "\n",
    "model.fit(X_tr[temporal_feat + lags_feat + ste_feat].astype(float), X_tr['y'])\n",
    "yhat = model.predict(X_tst[temporal_feat + lags_feat + ste_feat].astype(float))\n",
    "mae = mean_absolute_error(X_tst['y'], yhat, sample_weight=X_tst[\"y\"])\n",
    "bias = np.mean(yhat - X_tst['y'])\n",
    "\n",
    "print(f\"mean absolute erro is {mae} and bias equals to {bias}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sliced target encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean absolute erro is 5.542734322347635 and bias equals to -0.22450494464600132\n"
     ]
    }
   ],
   "source": [
    "ste_feat = []\n",
    "for c in cardinal_cat_cols:\n",
    "    fname = f\"te_{c}_last_28d_mean\"\n",
    "    te_feat = X_tr.groupby(c).nth(slice(-28, None)).groupby(c)[\"y\"].mean().to_frame(fname).reset_index()\n",
    "    X_tr = pd.merge(X_tr, te_feat, how=\"left\", on=c)\n",
    "    X_tst = pd.merge(X_tst, te_feat, how=\"left\", on=c)\n",
    "    ste_feat.append(fname)\n",
    "    \n",
    "\n",
    "model.fit(X_tr[temporal_feat + lags_feat + ste_feat].astype(float), X_tr['y'])\n",
    "yhat = model.predict(X_tst[temporal_feat + lags_feat + ste_feat].astype(float))\n",
    "mae = mean_absolute_error(X_tst['y'], yhat, sample_weight=X_tst[\"y\"])\n",
    "bias = np.mean(yhat - X_tst['y'])\n",
    "\n",
    "print(f\"mean absolute erro is {mae} and bias equals to {bias}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporal Target Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean absolute error is 5.185346477935068 and bias equals to -0.1781395220580267\n"
     ]
    }
   ],
   "source": [
    "wte_feat = []\n",
    "for c in cardinal_cat_cols:\n",
    "    for w in [28, 56, 90, 180]:\n",
    "        X[f\"windowed_te_{w}_{c}\"] = X.groupby(c)['y'].transform(lambda x : x.shift(HORIZON).rolling(w).mean())\n",
    "        wte_feat.append(f\"windowed_te_{w}_{c}\")\n",
    "    \n",
    "X_tr = X.loc[X[\"date\"] < start_validation]\n",
    "X_tst = X.loc[X[\"date\"] >= start_validation]\n",
    "\n",
    "model.fit(X_tr[temporal_feat + lags_feat + wte_feat].astype(float), X_tr['y'])\n",
    "yhat = model.predict(X_tst[temporal_feat + lags_feat + wte_feat].astype(float))\n",
    "mae = mean_absolute_error(X_tst['y'], yhat, sample_weight=X_tst[\"y\"])\n",
    "bias = np.mean(yhat - X_tst['y'])\n",
    "\n",
    "print(f\"mean absolute error is {mae} and bias equals to {bias}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trend Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "def simple_lr_trend(df, uid):\n",
    "    X = np.array((df[\"date\"] - df[\"date\"].min()).dt.days)[:, None]\n",
    "    y = np.log1p(df[\"y\"])\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "    trend = model.predict(X)\n",
    "    futures_dates = pd.date_range(df[\"date\"].max()+ pd.DateOffset(days=1), periods=28+1, freq=\"D\")\n",
    "    X_test = np.array((futures_dates - df[\"date\"].min()).days)[:, None]\n",
    "    test_trend_projec = model.predict(X_test)\n",
    "    shell = pd.DataFrame()\n",
    "    shell[\"date\"] = pd.date_range(df[\"date\"].min(), futures_dates[-1], freq=\"D\")\n",
    "    shell[\"uid\"] =  uid\n",
    "    shell[\"trend\"] = np.concatenate((trend, test_trend_projec), axis=0)\n",
    "    return shell\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in cardinal_cat_cols:\n",
    "    c_df = X_tr.groupby([\"date\"] + [c])['y'].sum().reset_index()\n",
    "    uid = c_df[c].unique()\n",
    "    with Parallel(n_jobs=-1) as parralel:\n",
    "        all_feats = parralel(delayed(simple_lr_trend)(c_df.query(f\"{c} == @ts_id\"), ts_id) for ts_id in uid)\n",
    "    all_feats_conc = pd.concat(all_feats)\n",
    "    all_feats_conc.columns = [\"date\", c, f\"{c}_trend\"]\n",
    "    X_tr = X_tr.merge(all_feats_conc, how=\"left\", on=[\"date\", c])\n",
    "    X_tst = X_tst.merge(all_feats_conc, how=\"left\", on=[\"date\", c])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean absolute error is 5.284021953529792 and bias equals to -0.16944617796217082\n"
     ]
    }
   ],
   "source": [
    "trend_feat = [\"item_id_trend_y\", \"store_id_trend_y\"] \n",
    "\n",
    "model.fit(X_tr[temporal_feat + lags_feat + trend_feat].astype(float), X_tr['y'])\n",
    "yhat = model.predict(X_tst[temporal_feat + lags_feat + trend_feat].astype(float))\n",
    "mae = mean_absolute_error(X_tst['y'], yhat, sample_weight=X_tst[\"y\"])\n",
    "bias = np.mean(yhat - X_tst['y'])\n",
    "\n",
    "print(f\"mean absolute error is {mae} and bias equals to {bias}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
