{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>state_id@store_id</th>\n",
       "      <th>d</th>\n",
       "      <th>y</th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>sell_price</th>\n",
       "      <th>start_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>115688</th>\n",
       "      <td>HOBBIES_2_149_TX_1_evaluation</td>\n",
       "      <td>HOBBIES_2_149</td>\n",
       "      <td>HOBBIES_2</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>TX_1</td>\n",
       "      <td>TX</td>\n",
       "      <td>TX@TX_1</td>\n",
       "      <td>d_1941</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-05-22</td>\n",
       "      <td>11617</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.97</td>\n",
       "      <td>2013-05-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115689</th>\n",
       "      <td>FOODS_3_718_CA_4_evaluation</td>\n",
       "      <td>FOODS_3_718</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_4</td>\n",
       "      <td>CA</td>\n",
       "      <td>CA@CA_4</td>\n",
       "      <td>d_1940</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-05-21</td>\n",
       "      <td>11617</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.48</td>\n",
       "      <td>2012-12-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115690</th>\n",
       "      <td>FOODS_3_718_CA_4_evaluation</td>\n",
       "      <td>FOODS_3_718</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_4</td>\n",
       "      <td>CA</td>\n",
       "      <td>CA@CA_4</td>\n",
       "      <td>d_1941</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-05-22</td>\n",
       "      <td>11617</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.48</td>\n",
       "      <td>2012-12-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115691</th>\n",
       "      <td>HOUSEHOLD_2_446_WI_2_evaluation</td>\n",
       "      <td>HOUSEHOLD_2_446</td>\n",
       "      <td>HOUSEHOLD_2</td>\n",
       "      <td>HOUSEHOLD</td>\n",
       "      <td>WI_2</td>\n",
       "      <td>WI</td>\n",
       "      <td>WI@WI_2</td>\n",
       "      <td>d_1940</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-05-21</td>\n",
       "      <td>11617</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.97</td>\n",
       "      <td>2013-02-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115692</th>\n",
       "      <td>HOUSEHOLD_2_446_WI_2_evaluation</td>\n",
       "      <td>HOUSEHOLD_2_446</td>\n",
       "      <td>HOUSEHOLD_2</td>\n",
       "      <td>HOUSEHOLD</td>\n",
       "      <td>WI_2</td>\n",
       "      <td>WI</td>\n",
       "      <td>WI@WI_2</td>\n",
       "      <td>d_1941</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-05-22</td>\n",
       "      <td>11617</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.97</td>\n",
       "      <td>2013-02-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id          item_id      dept_id  \\\n",
       "115688    HOBBIES_2_149_TX_1_evaluation    HOBBIES_2_149    HOBBIES_2   \n",
       "115689      FOODS_3_718_CA_4_evaluation      FOODS_3_718      FOODS_3   \n",
       "115690      FOODS_3_718_CA_4_evaluation      FOODS_3_718      FOODS_3   \n",
       "115691  HOUSEHOLD_2_446_WI_2_evaluation  HOUSEHOLD_2_446  HOUSEHOLD_2   \n",
       "115692  HOUSEHOLD_2_446_WI_2_evaluation  HOUSEHOLD_2_446  HOUSEHOLD_2   \n",
       "\n",
       "           cat_id store_id state_id state_id@store_id       d  y       date  \\\n",
       "115688    HOBBIES     TX_1       TX           TX@TX_1  d_1941  0 2016-05-22   \n",
       "115689      FOODS     CA_4       CA           CA@CA_4  d_1940  0 2016-05-21   \n",
       "115690      FOODS     CA_4       CA           CA@CA_4  d_1941  1 2016-05-22   \n",
       "115691  HOUSEHOLD     WI_2       WI           WI@WI_2  d_1940  0 2016-05-21   \n",
       "115692  HOUSEHOLD     WI_2       WI           WI@WI_2  d_1941  0 2016-05-22   \n",
       "\n",
       "        wm_yr_wk event_name_1 event_type_1 event_name_2 event_type_2  snap_CA  \\\n",
       "115688     11617          nan          nan          nan          nan        0   \n",
       "115689     11617          nan          nan          nan          nan        0   \n",
       "115690     11617          nan          nan          nan          nan        0   \n",
       "115691     11617          nan          nan          nan          nan        0   \n",
       "115692     11617          nan          nan          nan          nan        0   \n",
       "\n",
       "        snap_TX  snap_WI  sell_price start_date  \n",
       "115688        0        0        0.97 2013-05-07  \n",
       "115689        0        0        1.48 2012-12-29  \n",
       "115690        0        0        1.48 2012-12-29  \n",
       "115691        0        0       25.97 2013-02-12  \n",
       "115692        0        0       25.97 2013-02-12  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "skip = [f\"d_{i}\" for i in range(1, 700 + 1)] \n",
    "HORIZON = 28 # horizon de forecast\n",
    "CAT_COLS = ['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id']\n",
    "# spec de la hierarchie que l'on veut travaillÃ© \n",
    "spec = [\n",
    "    ['state_id', 'store_id', 'cat_id'], \n",
    "    ['state_id', 'store_id', 'cat_id', 'dept_id'],\n",
    "    ['state_id', 'store_id', 'cat_id', 'dept_id', 'item_id'],\n",
    "]\n",
    "\n",
    "calendar = pd.read_csv(\"C:/Users/n000193384/Downloads/awa_mooc/src/data/calendar.csv\", \n",
    "                       parse_dates=['date'],\n",
    "                       usecols=['date', 'd', 'wm_yr_wk', 'event_name_1', 'event_name_2', \n",
    "                                'event_type_1', 'event_type_2',\n",
    "                                'snap_CA', 'snap_TX', 'snap_WI']\n",
    ")\n",
    "\n",
    "event_cols = [k for k in calendar if k.startswith('event')]\n",
    "for col in event_cols:\n",
    "    calendar[col] = calendar[col].fillna('nan')\n",
    "    \n",
    "row_sales = pd.read_csv(\"C:/Users/n000193384/Downloads/awa_mooc/src/data/sales_train_evaluation.csv\").sample(100)\n",
    "prices = pd.read_csv('C:/Users/n000193384/Downloads/awa_mooc/src/data/sell_prices.csv')\n",
    "\n",
    "row_sales['state_id@store_id'] = row_sales['state_id'].astype(str) + \"@\" + row_sales['store_id'].astype(str)\n",
    "all_state_and_store = np.unique(row_sales['state_id@store_id'])\n",
    "\n",
    "# formattage ligne et renommage des colonnes pour respecter les conventions de la librairie.\n",
    "train = (row_sales\n",
    "         .drop(skip, axis=1)\n",
    "         .pipe(pd.melt, \n",
    "               id_vars=[\"id\", \"item_id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\", \"state_id@store_id\"],\n",
    "               var_name='d',\n",
    "               value_name=\"y\"\n",
    "               )\n",
    "         .merge(calendar, how=\"left\", on=[\"d\"])\n",
    "         .merge(prices, on=[\"store_id\", \"item_id\", \"wm_yr_wk\"])\n",
    "        )\n",
    "\n",
    "st_idx = (train\n",
    "          .loc[(train['y'] > 0) & train['sell_price'].notnull()]\n",
    "          .groupby('id', as_index=False)\n",
    "          .agg(start_date = ('date', 'min'))\n",
    ")\n",
    "\n",
    "train = train.merge(st_idx, how=\"left\", on=[\"id\"]).query('date>=start_date')\n",
    "\n",
    "future_cal = calendar[calendar['date'] >  train['date'].max()]\n",
    "future_prices = prices[prices['wm_yr_wk'] >= train['wm_yr_wk'].max()].copy()\n",
    "future_prices['id'] = future_prices['item_id'].astype(str) + '_' + future_prices['store_id'].astype(str) + '_evaluation'\n",
    "X_df = future_prices.merge(future_cal, on='wm_yr_wk').drop(columns=['store_id', 'item_id', 'wm_yr_wk', 'd'])\n",
    "\n",
    "# extract all series id\n",
    "train.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.cache/pypoetry/virtualenvs/mawa-A94Yhi_h-py3.10/lib/python3.10/site-packages/mlforecast/core.py:209: UserWarning: Setting num_threads to 1.\n",
      "  warnings.warn(\"Setting num_threads to 1.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>LGBMRegressor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FOODS_1_001_CA_1_evaluation</td>\n",
       "      <td>2016-05-23</td>\n",
       "      <td>0.777874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FOODS_1_001_CA_1_evaluation</td>\n",
       "      <td>2016-05-24</td>\n",
       "      <td>0.702040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FOODS_1_001_CA_1_evaluation</td>\n",
       "      <td>2016-05-25</td>\n",
       "      <td>0.624894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FOODS_1_001_CA_1_evaluation</td>\n",
       "      <td>2016-05-26</td>\n",
       "      <td>0.684752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FOODS_1_001_CA_1_evaluation</td>\n",
       "      <td>2016-05-27</td>\n",
       "      <td>0.700597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853715</th>\n",
       "      <td>HOUSEHOLD_2_516_WI_3_evaluation</td>\n",
       "      <td>2016-06-15</td>\n",
       "      <td>0.151102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853716</th>\n",
       "      <td>HOUSEHOLD_2_516_WI_3_evaluation</td>\n",
       "      <td>2016-06-16</td>\n",
       "      <td>0.162570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853717</th>\n",
       "      <td>HOUSEHOLD_2_516_WI_3_evaluation</td>\n",
       "      <td>2016-06-17</td>\n",
       "      <td>0.188832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853718</th>\n",
       "      <td>HOUSEHOLD_2_516_WI_3_evaluation</td>\n",
       "      <td>2016-06-18</td>\n",
       "      <td>0.204748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853719</th>\n",
       "      <td>HOUSEHOLD_2_516_WI_3_evaluation</td>\n",
       "      <td>2016-06-19</td>\n",
       "      <td>0.194041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>853720 rows Ã 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id       date  LGBMRegressor\n",
       "0           FOODS_1_001_CA_1_evaluation 2016-05-23       0.777874\n",
       "1           FOODS_1_001_CA_1_evaluation 2016-05-24       0.702040\n",
       "2           FOODS_1_001_CA_1_evaluation 2016-05-25       0.624894\n",
       "3           FOODS_1_001_CA_1_evaluation 2016-05-26       0.684752\n",
       "4           FOODS_1_001_CA_1_evaluation 2016-05-27       0.700597\n",
       "...                                 ...        ...            ...\n",
       "853715  HOUSEHOLD_2_516_WI_3_evaluation 2016-06-15       0.151102\n",
       "853716  HOUSEHOLD_2_516_WI_3_evaluation 2016-06-16       0.162570\n",
       "853717  HOUSEHOLD_2_516_WI_3_evaluation 2016-06-17       0.188832\n",
       "853718  HOUSEHOLD_2_516_WI_3_evaluation 2016-06-18       0.204748\n",
       "853719  HOUSEHOLD_2_516_WI_3_evaluation 2016-06-19       0.194041\n",
       "\n",
       "[853720 rows x 3 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlforecast import MLForecast\n",
    "from mlforecast.lag_transforms import ExpandingMean, RollingMean, SeasonalRollingMean\n",
    "import lightgbm as lgb \n",
    "\n",
    "# paramÃ¨tre basique pour le lightgbm\n",
    "model_params = {\n",
    "    'verbose': -1,\n",
    "    'force_col_wise': True,\n",
    "    'num_leaves': 100,\n",
    "    'n_estimators': 100,\n",
    "}\n",
    "\n",
    "fcst = MLForecast(\n",
    "    models=[lgb.LGBMRegressor(**model_params)],\n",
    "    freq='D',\n",
    "    lags=[7 * (i+1) for i in range(8)],\n",
    "    lag_transforms = {\n",
    "        1:  [ExpandingMean()],\n",
    "        7:  [RollingMean(7), RollingMean(14), RollingMean(28), SeasonalRollingMean(7, 4)],\n",
    "        14: [RollingMean(7), RollingMean(14), RollingMean(28), SeasonalRollingMean(7, 4)],\n",
    "        28: [RollingMean(7), RollingMean(14), RollingMean(28), SeasonalRollingMean(7, 4)],\n",
    "    },\n",
    "    date_features=['month', 'day', 'dayofweek', 'quarter', 'week'],    \n",
    "    num_threads=-1,\n",
    ")\n",
    "\n",
    "fcst.fit(\n",
    "    train,\n",
    "    id_col='id',\n",
    "    time_col='date',\n",
    "    target_col='y',\n",
    "    static_features=['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'],\n",
    ")\n",
    "\n",
    "bottom_level_forecast = fcst.predict(28, X_df=X_df)\n",
    "bottom_level_forecast.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toplevel = (train\n",
    "            .groupby(['state_id', 'store_id', 'cat_id', 'date'], as_index=False)\n",
    "            .agg(y=('y', 'sum'))\n",
    "            .assign(unique_id = lambda x : x['state_id'].astype(str) + '@' + x['store_id'].astype(str) + '@' + x['cat_id'].astype('str'))\n",
    "            .rename(columns={\"date\":\"ds\"})\n",
    ")[[\"unique_id\", \"ds\", \"y\"]]\n",
    "\n",
    "\n",
    "from statsforecast import StatsForecast\n",
    "from statsforecast.models import (\n",
    "    AutoETS,\n",
    "    DynamicOptimizedTheta,\n",
    "    AutoCES,\n",
    "    AutoARIMA, \n",
    "    MSTL,\n",
    "    SeasonalWindowAverage\n",
    ")\n",
    "\n",
    "# on s'attend Ã  un effet hebdomadaire.\n",
    "EXPECTED_SEASONAL_VALUE = 30\n",
    "HORIZON = 28\n",
    "\n",
    "# Les modÃ¨les qui vont Ãªtre \"fittÃ©\"\n",
    "models = [\n",
    "    AutoETS(season_length=EXPECTED_SEASONAL_VALUE),\n",
    "    DynamicOptimizedTheta(season_length=EXPECTED_SEASONAL_VALUE),\n",
    "    AutoCES(season_length=EXPECTED_SEASONAL_VALUE),\n",
    "    MSTL(\n",
    "        season_length=[EXPECTED_SEASONAL_VALUE, 90], # seasonalities of the time series\n",
    "        trend_forecaster=AutoARIMA() # model used to forecast trend\n",
    "    )\n",
    "]\n",
    "\n",
    "# le wrapper.\n",
    "wrapper_models = StatsForecast( \n",
    "    models=models,\n",
    "    freq='D', \n",
    "    n_jobs=-1,\n",
    "    fallback_model=SeasonalWindowAverage(season_length=EXPECTED_SEASONAL_VALUE, window_size=HORIZON)\n",
    ")\n",
    "\n",
    "toplevel_forecast = wrapper_models.forecast(df=train, h=HORIZON).assign(blend_yhat=lambda x : x.clip(0, None).median(axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hat_df = bottom_level_forecast.append(toplevel)\n",
    "\n",
    "from hierarchicalforecast.utils import aggregate\n",
    "from hierarchicalforecast.core import HierarchicalReconciliation\n",
    "from hierarchicalforecast.methods import BottomUp, TopDown, MinTrace, ERM, OptimalCombination\n",
    "\n",
    "bottom_fcst = [\n",
    "    'LGBMRegressor', \n",
    "    'LGBMRegressor/BottomUp',\n",
    "    'LGBMRegressor/TopDown_method-forecast_proportions',\n",
    "    'LGBMRegressor/MinTrace_method-ols', \n",
    "    'LGBMRegressor/MinTrace_method-mint_shrink'\n",
    "    ]\n",
    "    \n",
    "# Reconcile the base predictions\n",
    "reconcilers = [\n",
    "    BottomUp(),\n",
    "    TopDown(method='forecast_proportions'),\n",
    "    MinTrace(method='ols'),\n",
    "    MinTrace(method='mint_shrink'),\n",
    "    ERM('reg'),\n",
    "    OptimalCombination(\"ols\")\n",
    "]\n",
    "hrec = HierarchicalReconciliation(reconcilers=reconcilers)\n",
    "\n",
    "apd = []\n",
    "for store in all_store:\n",
    "    Y_df, S_df, tags = aggregate(\n",
    "        train.loc[train['state_id@store_id'] == store].rename(columns={'date':'ds'}),\n",
    "        spec\n",
    "    )\n",
    "    # get series\n",
    "    all_series_at_bottom = tags['state_id/store_id/cat_id/dept_id/item_id']\n",
    "    \n",
    "    Y_rec_df = hrec.reconcile(Y_hat_df=Y_hat_df, \n",
    "                              Y_df=train[['unique_id', 'ds', 'y']].append(toplevel),  # Y_fitted_df,\n",
    "                              S=S_df,\n",
    "                              tags=tags)\n",
    "\n",
    "    rec_df = (Y_rec_df\n",
    "                    .loc[all_series_at_bottom]\n",
    "                    .assign(blend_fcst=lambda x : x[bottom_fcst].mean(axis=1))\n",
    "                    .reset_index(names=\"unique_id\")\n",
    "                     .assign(unique_id= lambda x : (x['unique_id'].str.split('/', expand=True).iloc[:, -1]\n",
    "                                + '_' +\n",
    "                                x['unique_id'].str.split('/', expand=True).iloc[:, 1]) \n",
    "                                + '_evaluation'\n",
    "        )\n",
    "                   )\n",
    "    apd.append(rec_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_4033/360325389.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  evaluation[\"id\"] = evaluation[\"id\"].str.replace(\"evaluation\", \"validation\")\n"
     ]
    }
   ],
   "source": [
    "def make_submission(test, fcst_col=\"\", filename=\"\"):\n",
    "    # private leaderboard\n",
    "    submission = pd.read_csv(\"/home/jupyter/mawa/data/sample_submission.csv\")\n",
    "    predictions = test[['id', 'date', fcst_col]]\n",
    "    predictions = pd.pivot(predictions, index='id', columns='date', values=fcst_col).reset_index()\n",
    "    predictions.columns = ['id'] + ['F' + str(i + 1) for i in range(28)]\n",
    "\n",
    "    # public leaderboard set to 0\n",
    "    evaluation_rows = [row for row in submission['id'] if 'evaluation' in row]\n",
    "    evaluation = submission[submission['id'].isin(evaluation_rows)]\n",
    "    evaluation[\"id\"] = evaluation[\"id\"].str.replace(\"evaluation\", \"validation\")\n",
    "\n",
    "    validation = submission[['id']].merge(predictions, on='id')\n",
    "    final = pd.concat([validation, evaluation])\n",
    "    final.iloc[:, 1:] = final.iloc[:, 1:].astype(np.float32)\n",
    "    final.to_csv(f'submission_{filename}.csv.gz', index=False, compression=\"gzip\")\n",
    "\n",
    "\n",
    "\n",
    "make_submission((preds\n",
    "                 .reset_index()\n",
    "                 .assign(yhat=lambda x: pd.to_numeric(np.around(x[\"LGBMRegressor\"], 2).clip(0, None)))\n",
    "                 .assign(id=lambda x : x['id'])\n",
    "                ),\n",
    "                fcst_col=\"yhat\", filename=f\"mlforecast\"\n",
    "               )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "fcst",
   "name": "common-cpu.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m112"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
